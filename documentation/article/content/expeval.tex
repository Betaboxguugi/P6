\section{Evaluation}\label{sect:eval}
In the following section we will evaluate and determine whether we have fulfilled the goals which we set out to accomplish for \FW{}. At first we will describe on what criteria we based the evaluation on. In the following section we will then elaborate on the setup of our actual evaluation. Then finally discuss and show the result from our evaluation.

\subsection{Criteria of Evaluation}\label{subsect:CoE}
%Framework vs. Manuel
%Focus on what the programmers need to do.
%Number of  statements
%Performance testing will not be a focus but mentioned, so it becomes clear execution time is non issue problem. 
As of writing this article, there exist no other test framework made to work in conjunction with pygrametl. So we lack something to evaluate against and existing tools for testing ETL processes, such as QuerySurge and AnyDBTest, are not good to evaluate against either. Such tools are simply too dissimilar, as they have use of an user interface and lack coding as the primary tool to set up the DW. We will therefore only evaluate \FW{} against manual testing, as we believe that as of now, it is the only alternative when testing ETL processes made by pygrametl. Now that we have determined what we will evaluate \FW{} against, we would like conclude with some certainty which, of \FW{} or manual testing, is the best for testing ETL processes for pygrametl. To do so we set up the following criteria:

\begin{description}
\item[Time needed in setting up a test] Best solution is the one with shortest time used, as because of the time saved in developing or maintaining a product. This leaves more time for other endeavours, often improving the quality of the product.
\item[Number of statements used] Best solution is the one with with fewest amount of statements used, as its reduces complexity. Reducing complexity often help with readability, which in turn makes it easier find the various bugs that might be in ones product.
\end{description}
Beside this, we will also note the execution time between \FW{} and manual testing. We do not evaluate anything based on this, as execution time is not largely relevant when performing tests. But we still note it, to determine if \FW{} is noticeable slower or faster compared to manual testing.

\subsection{Setup of Evaluation}
Based on the criteria described in \cref{subsect:CoE}, we will now describe the actual case for the evaluation and how its devised. At first we made an pygrametl program, to run our tests against. This pygrametl program, sets up a DW, which contains 4 tables, author, book, country and fact\_table respectively. The DW follows a snowflake schema with country linked to author. The table book is a slowly changing dimension unlike the other tables.
The DW is lastly populated by the program, the data inserted filled with various faults, which we intend to catch with our predicates and manual tests.
We then time our testing attempts individually, both \FW{} and manual test, against this pygrametl program, so that we can note the difference in time used. Each testing attempt will be for each of the different predicates we have in \FW{}, with manual testing testing for the same. They do not need to give the same output however, as long as they both conclude whether the assertion of the predicate holds or not. Once all tests have been run we will count the number of statements used in each attempt and note their execution time.

%Pygrametl program with errors.
%Same program tested for framework versus manual
%Timed
%Number of statements counted

\subsection{Results}
\todo[inline]{As seen below we can clearly see that our solution is the best! :D For real though, do the evaluation then write this section and fill the following table with the results}

\begin{table}[h]
\centering
\caption{Result of Evaluation}
\label{table:result}
\begin{tabular}{|p{0.10\textwidth}|p{0.15\textwidth}|p{0.15\textwidth}|}
\hline
												& \FW{}	 	& Manual				  \\ \hline
Lines of code					 	& 41      & 140          		\\ \hline
Number of statements   	& 26      & 46             	\\ \hline
Average Execution Time	& 0.93s   & 0.0s           	\\ \hline
\end{tabular}
\end{table}








